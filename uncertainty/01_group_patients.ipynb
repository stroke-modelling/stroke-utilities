{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b6e394-b2ab-49c8-9c2a-f013a37ccb7a",
   "metadata": {},
   "source": [
    "# 1: Group patients by similar features\n",
    "\n",
    "## Plain English summary\n",
    "\n",
    "This notebook defines many different \"types\" of patients. Each group of patients has similar properties, and for each group we look at all nine of the features that will be used in the machine learning model. This notebook defines 576 different groups, places the 10,000 patients in the test data into those groups, and saves a record of the group assignments for later. \n",
    "\n",
    "The groups are not divided up too finely otherwise there would not be very many people in any group.\n",
    "Also, two of the times in the patient data have been combined into one new value. We use onset-to-scan time instead of separate onset-to-arrival and arrival-to-scan times. If they were kept separate, there would be too few patients in any group.\n",
    "\n",
    "The patients are grouped by:\n",
    "\n",
    "| Feature | Options |\n",
    "| --- | --- |\n",
    "| Stroke severity | Mild, moderate, severe |\n",
    "| Prior disability | Mild (mRS 0 or 1), moderate (mRS 2 or 3), severe (mRS 4 or 5) |\n",
    "| Age | Below 80, 80 or higher |\n",
    "| Infarction | Yes, no |\n",
    "| Onset to _scan_ time | Below four hours, at least four hours |\n",
    "| Precise onset known | Yes, no |\n",
    "| Onset during sleep | Yes, no |\n",
    "| Afib anticoagulants | Yes, no |\n",
    "\n",
    "All of the different combinations of these features make $3 \\times 3 \\times 2 \\times 2 \\times 2 \\times 2 \\times 2 \\times 2  = 576$ groups.\n",
    "\n",
    "This notebook also uses the trained machine learning model to predict the probability of thrombolysis for each patient in the test data. This means we can save a data file with each patient, their group number, and their probability of thrombolysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6844e-eb5b-4f48-b3fc-c89f2d0d82df",
   "metadata": {},
   "source": [
    "## Load imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce754934-f861-4193-a0c5-cb5174e42c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import stroke_utilities.process_data as process_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da1f55-0565-465c-82c9-c6751d0fd2a6",
   "metadata": {},
   "source": [
    "## Set up paths and filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "237c3ee3-91bc-4df2-86a3-933b89e54b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Paths:\n",
    "    '''Singleton object for storing paths to data and database.'''\n",
    "\n",
    "    data_read_path: str = './stroke_utilities/data/'\n",
    "    data_read_filename: str = 'reformatted_data_thrombolysis_decision.csv'\n",
    "    data_test_filename: str = 'cohort_10000_test.csv'\n",
    "    data_train_filename: str = 'cohort_10000_train.csv'\n",
    "    data_save_path: str = './stroke_utilities/data'\n",
    "    model_folder = './stroke_utilities/models'\n",
    "    notebook: str = ''\n",
    "\n",
    "paths = Paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a667ba7-b3c4-48b5-9f51-30fb3af7dd71",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Import the trained machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e58418f2-5284-4e01-83aa-2f023bc4c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{paths.model_folder}/model.p', 'rb') as fp:\n",
    "    model = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc18d5a-3f9f-487e-8ce3-a61d68eacabc",
   "metadata": {},
   "source": [
    "Import the patient data. The following cell imports just the 10000 patients in the test data and splits it into X and y for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5aeae11-0a59-49d3-bdb1-c789dc604395",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = paths.data_read_path + paths.data_test_filename\n",
    "test = pd.read_csv(filename)\n",
    "\n",
    "X_test, y_test = process_data.split_X_and_y(test, 'thrombolysis')\n",
    "\n",
    "data = process_data.one_hot_encode_column(\n",
    "    X_test, 'stroke_team_id', prefix='team')\n",
    "data = data.drop('year', axis=1)\n",
    "\n",
    "save_str = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3b0e2-d0e2-472e-b0fe-f255396befcc",
   "metadata": {},
   "source": [
    "Alternative: import the _training_ patient data. The following cell imports just the ~100,000 patients in the training data and splits it into X and y for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70e73072-2c54-43fe-aebe-efe23cf1fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = 1\n",
    "if training == 1:\n",
    "    filename = paths.data_read_path + paths.data_train_filename\n",
    "    train = pd.read_csv(filename)\n",
    "    \n",
    "    X_train, y_train = process_data.split_X_and_y(train, 'thrombolysis')\n",
    "    \n",
    "    data = process_data.one_hot_encode_column(\n",
    "        X_train, 'stroke_team_id', prefix='team')\n",
    "    data = data.drop('year', axis=1)\n",
    "    \n",
    "    save_str = 'train_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55862e15-6f1f-427d-b998-4fe9c5f03196",
   "metadata": {},
   "source": [
    "Alternative: import the patient data for all ~110,000 patients, not just the 10,000 test patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e3f76ee-6ef9-448e-ba32-4429874a712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients = 0\n",
    "if all_patients == 1:\n",
    "    filename = paths.data_read_path + paths.data_read_filename\n",
    "    data = pd.read_csv(filename)\n",
    "    \n",
    "    \n",
    "    # Ensure all values are float and shuffle\n",
    "    \n",
    "    data = data.sample(frac=1.0, random_state=42)\n",
    "    \n",
    "    ## Limit to scan with enough time for thrombolysis\n",
    "    \n",
    "    with open('./stroke_utilities/fixed_params.yml') as f:\n",
    "        fixed_params = yaml.safe_load(f)\n",
    "    \n",
    "    # allowed_onset_to_needle_time_mins = fixed_params['allowed_onset_to_needle_time_mins']\n",
    "    # minutes_left = fixed_params['minutes_left']\n",
    "    allowed_onset_to_scan_time = fixed_params['allowed_onset_to_scan_time']\n",
    "    \n",
    "    def restrict_to_onset_to_scan_on_time(big_data):    \n",
    "        # Time left after scan for thrombolysis\n",
    "        big_data['onset_to_scan_time'] = (\n",
    "            big_data['onset_to_arrival_time'] + \n",
    "            big_data['arrival_to_scan_time']\n",
    "            )\n",
    "    \n",
    "        mask_to_include = big_data['onset_to_scan_time'] <= allowed_onset_to_scan_time\n",
    "    \n",
    "        # Restrict the data to these patients:\n",
    "        big_data = big_data[mask_to_include]\n",
    "        return big_data\n",
    "    \n",
    "    data = restrict_to_onset_to_scan_on_time(data)\n",
    "    \n",
    "    # mask = data['onset_to_arrival_time'] <= 240\n",
    "    # data = data[mask]\n",
    "    \n",
    "    ## Limit to 10 features and thrombolysis label\n",
    "    \n",
    "    features_to_use = [\n",
    "        'stroke_team_id',\n",
    "        'stroke_severity',\n",
    "        'prior_disability',\n",
    "        'age',\n",
    "        'infarction',\n",
    "        'onset_to_arrival_time',\n",
    "        'precise_onset_known',\n",
    "        'onset_during_sleep',\n",
    "        'arrival_to_scan_time',\n",
    "        'afib_anticoagulant',\n",
    "        'year',    \n",
    "        'thrombolysis'\n",
    "    ]\n",
    "    \n",
    "    data = data[features_to_use]\n",
    "\n",
    "    save_str = 'cleaned_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ed4425-6905-4207-aebd-0032722735e8",
   "metadata": {},
   "source": [
    "## Define groups\n",
    "\n",
    "Set up the groups by defining how many options there are for each feature. They are called \"masks\" because the feature options will be used to mask out unwanted patients from the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd3b4f66-80aa-4334-840e-75e6b89d7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many masks are in each category?\n",
    "masks = {\n",
    "    'onset_scan':2,\n",
    "    'severity':3,\n",
    "    'mrs':3,\n",
    "    'age':2,\n",
    "    'infarction':2,\n",
    "    'precise':2,\n",
    "    'sleep':2,\n",
    "    'anticoag':2\n",
    "}\n",
    "masks_names = list(masks.keys())\n",
    "masks_lens = list(masks.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835358cf-27df-4e3d-a39a-e813dbd0dda0",
   "metadata": {},
   "source": [
    "Also store a way to convert the number labels back to more meaningful labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47dde704-6dc8-449c-a084-14be5b6c9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_str_dict = {\n",
    "    'onset_scan':{0:'<=4hr', 1:'>4hr'},\n",
    "    'severity':{0:'Mild', 1:'Moderate', 2:'Severe'},\n",
    "    'mrs':{0:'0 to 1', 1:'2 to 3', 2:'4 to 5'},\n",
    "    'age':{0:'Below 80', 1:'At least 80'},\n",
    "    'infarction':{0:'No', 1:'Yes'},\n",
    "    'precise':{0:'No', 1:'Yes'},\n",
    "    'sleep':{0:'No', 1:'Yes'},\n",
    "    'anticoag':{0:'No', 1:'Yes'},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65171eb0-eb5d-416d-b811-3bc2088778e4",
   "metadata": {},
   "source": [
    "Name each feature option as a number (option 0, 1, 2...). Find every unique combination of these feature options and store the lists of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58d18d5a-f24b-4523-ab26-2f4e2b24f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be written more compactly but it works for now:\n",
    "inds_lists = []\n",
    "\n",
    "for a in range(masks_lens[0]):\n",
    "    for b in range(masks_lens[1]):\n",
    "        for c in range(masks_lens[2]):\n",
    "            for d in range(masks_lens[3]):\n",
    "                for e in range(masks_lens[4]):\n",
    "                    for f in range(masks_lens[5]):\n",
    "                        for g in range(masks_lens[6]):\n",
    "                            for h in range(masks_lens[7]):\n",
    "                                inds_lists.append([a, b, c, d, e, f, g, h])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32535d6c-b8c3-4dc3-b8de-3a5ec0afa92e",
   "metadata": {},
   "source": [
    "The first few combinations look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c009431c-1bc8-4d50-a43c-f660b83cc720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 1, 1]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds_lists[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb470cc-1144-4030-a5fd-ff30a4ac0d0e",
   "metadata": {},
   "source": [
    "Place these lists of lists into a dataframe so that we can label which number belongs to which feature. Also create a new column, `mask_number`, to label each unique combination of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "384fc315-a7e8-4b1c-8ca1-f70b3259b656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset_scan_mask_number</th>\n",
       "      <th>severity_mask_number</th>\n",
       "      <th>mrs_mask_number</th>\n",
       "      <th>age_mask_number</th>\n",
       "      <th>infarction_mask_number</th>\n",
       "      <th>precise_mask_number</th>\n",
       "      <th>sleep_mask_number</th>\n",
       "      <th>anticoag_mask_number</th>\n",
       "      <th>mask_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     onset_scan_mask_number  severity_mask_number  mrs_mask_number  \\\n",
       "0                         0                     0                0   \n",
       "1                         0                     0                0   \n",
       "2                         0                     0                0   \n",
       "3                         0                     0                0   \n",
       "4                         0                     0                0   \n",
       "..                      ...                   ...              ...   \n",
       "571                       1                     2                2   \n",
       "572                       1                     2                2   \n",
       "573                       1                     2                2   \n",
       "574                       1                     2                2   \n",
       "575                       1                     2                2   \n",
       "\n",
       "     age_mask_number  infarction_mask_number  precise_mask_number  \\\n",
       "0                  0                       0                    0   \n",
       "1                  0                       0                    0   \n",
       "2                  0                       0                    0   \n",
       "3                  0                       0                    0   \n",
       "4                  0                       0                    1   \n",
       "..               ...                     ...                  ...   \n",
       "571                1                       1                    0   \n",
       "572                1                       1                    1   \n",
       "573                1                       1                    1   \n",
       "574                1                       1                    1   \n",
       "575                1                       1                    1   \n",
       "\n",
       "     sleep_mask_number  anticoag_mask_number  mask_number  \n",
       "0                    0                     0            0  \n",
       "1                    0                     1            1  \n",
       "2                    1                     0            2  \n",
       "3                    1                     1            3  \n",
       "4                    0                     0            4  \n",
       "..                 ...                   ...          ...  \n",
       "571                  1                     1          571  \n",
       "572                  0                     0          572  \n",
       "573                  0                     1          573  \n",
       "574                  1                     0          574  \n",
       "575                  1                     1          575  \n",
       "\n",
       "[576 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mask_numbers = pd.DataFrame(inds_lists, columns=[m + '_mask_number' for m in masks_names])\n",
    "\n",
    "df_mask_numbers['mask_number'] = np.arange(len(df_mask_numbers))\n",
    "\n",
    "df_mask_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992af34-08bf-4657-b816-17ca1d7877ed",
   "metadata": {},
   "source": [
    "Save the mask combinations and their labels to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96516e44-d2d0-4333-9ac0-2c8ca280e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask_numbers.to_csv(f'./uncertainty/{save_str}mask_numbers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caa313-7701-4454-ae55-f9cc51325aaa",
   "metadata": {},
   "source": [
    "Translate the numbers back to strings for a better look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8077a861-c62e-45bb-97bf-40419dc67bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset_scan</th>\n",
       "      <th>severity</th>\n",
       "      <th>mrs</th>\n",
       "      <th>age</th>\n",
       "      <th>infarction</th>\n",
       "      <th>precise</th>\n",
       "      <th>sleep</th>\n",
       "      <th>anticoag</th>\n",
       "      <th>mask_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=4hr</td>\n",
       "      <td>Mild</td>\n",
       "      <td>0 to 1</td>\n",
       "      <td>Below 80</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=4hr</td>\n",
       "      <td>Mild</td>\n",
       "      <td>0 to 1</td>\n",
       "      <td>Below 80</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;=4hr</td>\n",
       "      <td>Mild</td>\n",
       "      <td>0 to 1</td>\n",
       "      <td>Below 80</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;=4hr</td>\n",
       "      <td>Mild</td>\n",
       "      <td>0 to 1</td>\n",
       "      <td>Below 80</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=4hr</td>\n",
       "      <td>Mild</td>\n",
       "      <td>0 to 1</td>\n",
       "      <td>Below 80</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>&gt;4hr</td>\n",
       "      <td>Severe</td>\n",
       "      <td>4 to 5</td>\n",
       "      <td>At least 80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>&gt;4hr</td>\n",
       "      <td>Severe</td>\n",
       "      <td>4 to 5</td>\n",
       "      <td>At least 80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>&gt;4hr</td>\n",
       "      <td>Severe</td>\n",
       "      <td>4 to 5</td>\n",
       "      <td>At least 80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>&gt;4hr</td>\n",
       "      <td>Severe</td>\n",
       "      <td>4 to 5</td>\n",
       "      <td>At least 80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>&gt;4hr</td>\n",
       "      <td>Severe</td>\n",
       "      <td>4 to 5</td>\n",
       "      <td>At least 80</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    onset_scan severity     mrs          age infarction precise sleep  \\\n",
       "0        <=4hr     Mild  0 to 1     Below 80         No      No    No   \n",
       "1        <=4hr     Mild  0 to 1     Below 80         No      No    No   \n",
       "2        <=4hr     Mild  0 to 1     Below 80         No      No   Yes   \n",
       "3        <=4hr     Mild  0 to 1     Below 80         No      No   Yes   \n",
       "4        <=4hr     Mild  0 to 1     Below 80         No     Yes    No   \n",
       "..         ...      ...     ...          ...        ...     ...   ...   \n",
       "571       >4hr   Severe  4 to 5  At least 80        Yes      No   Yes   \n",
       "572       >4hr   Severe  4 to 5  At least 80        Yes     Yes    No   \n",
       "573       >4hr   Severe  4 to 5  At least 80        Yes     Yes    No   \n",
       "574       >4hr   Severe  4 to 5  At least 80        Yes     Yes   Yes   \n",
       "575       >4hr   Severe  4 to 5  At least 80        Yes     Yes   Yes   \n",
       "\n",
       "    anticoag  mask_number  \n",
       "0         No            0  \n",
       "1        Yes            1  \n",
       "2         No            2  \n",
       "3        Yes            3  \n",
       "4         No            4  \n",
       "..       ...          ...  \n",
       "571      Yes          571  \n",
       "572       No          572  \n",
       "573      Yes          573  \n",
       "574       No          574  \n",
       "575      Yes          575  \n",
       "\n",
       "[576 rows x 9 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mask_labels = df_mask_numbers.copy()\n",
    "\n",
    "# Remove the _mask_number part of the columns:\n",
    "df_mask_labels = df_mask_labels.rename(\n",
    "    columns=dict(zip([m + '_mask_number' for m in masks_names], masks_names))\n",
    ")\n",
    "\n",
    "# Replace numbers with labels:\n",
    "df_mask_labels = df_mask_labels.replace(mask_str_dict)\n",
    "\n",
    "df_mask_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173968f-e296-4edf-8f1b-d7a267edfa65",
   "metadata": {},
   "source": [
    "## Place patients into groups\n",
    "\n",
    "Before we set up a labelling system for all of the combinations of masks. Now we will actually find the mask belonging to each label.\n",
    "\n",
    "The patient data is used and checked against each condition (e.g. is the stroke severity mild? Is it moderate? Is it severe?) and an answer of True or False is stored for each patient in every case. For the test data, each mask contains 10,000 True and False values.\n",
    "\n",
    "The following cell creates a dictionary. The dictionary contains a list of masks for each feature. Each list is a different length depending on how many options there are for the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41362a04-3bbf-46d6-a0f4-8efdc89a6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_severity = [\n",
    "    (data['stroke_severity'] < 8),\n",
    "    ((data['stroke_severity'] >= 8) & (data['stroke_severity'] <= 32)),\n",
    "    (data['stroke_severity'] > 32)\n",
    "    ]\n",
    "masks_mrs = [\n",
    "    ((data['prior_disability'] == 0) | (data['prior_disability'] == 1)),\n",
    "    ((data['prior_disability'] == 2) | (data['prior_disability'] == 3)),\n",
    "    ((data['prior_disability'] == 4) | (data['prior_disability'] == 5)),\n",
    "    ]\n",
    "masks_age = [\n",
    "    (data['age'] < 80),\n",
    "    (data['age'] >= 80)\n",
    "    ]\n",
    "masks_infarction = [\n",
    "    (data['infarction'] == 0),\n",
    "    (data['infarction'] != 0)\n",
    "    ]\n",
    "masks_onset_scan = [\n",
    "    (data['onset_to_arrival_time'] + data['arrival_to_scan_time'] <= 4*60),\n",
    "    (data['onset_to_arrival_time'] + data['arrival_to_scan_time'] > 4*60)\n",
    "    ]\n",
    "masks_precise = [\n",
    "    (data['precise_onset_known'] == 0),\n",
    "    (data['precise_onset_known'] != 0)\n",
    "    ]\n",
    "masks_sleep = [\n",
    "    (data['onset_during_sleep'] == 0),\n",
    "    (data['onset_during_sleep'] != 0)\n",
    "    ]\n",
    "masks_anticoag = [\n",
    "    (data['afib_anticoagulant'] == 0),\n",
    "    (data['afib_anticoagulant'] != 0)\n",
    "    ]\n",
    "\n",
    "# Store the masks in a dictionary:\n",
    "masks = {\n",
    "    'onset_scan':masks_onset_scan,\n",
    "    'severity':masks_severity,\n",
    "    'mrs':masks_mrs,\n",
    "    'age':masks_age,\n",
    "    'infarction':masks_infarction,\n",
    "    'precise':masks_precise,\n",
    "    'sleep':masks_sleep,\n",
    "    'anticoag':masks_anticoag\n",
    "}\n",
    "masks_names = list(masks.keys())\n",
    "masks_lists = list(masks.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec36a2-7358-46b6-a89d-2d0e41aa16a2",
   "metadata": {},
   "source": [
    "For each of the 576 combinations of feature values, pick out the relevant masks from the above dictionary. Then multiply all eight of the chosen masks together. This means that only patients who answer True to each of the eight masks will end up as True in the combined mask.\n",
    "\n",
    "The list `group_masks` will then let us pick out only the patients who belong to a certain group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "654e9af2-adc1-4546-a769-e904415b37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_masks = []\n",
    "\n",
    "for inds in inds_lists:\n",
    "    # Patient assigned 1 if all masks are 1, else 0 (using np.product to multiply masks).\n",
    "    group_masks.append(np.product([masks_lists[m][i] for m, i in enumerate(inds)], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37504b02-040a-4b56-b832-d7ff6a717798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_groups = len(group_masks)\n",
    "\n",
    "n_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9a25a-e68a-4bad-a093-ffcb42eae8ab",
   "metadata": {},
   "source": [
    "Then convert this into a list of 10000 numbers. This is the complete ordered list of group number by patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c82289d-c0b3-41c9-a591-4443d801009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575\r"
     ]
    }
   ],
   "source": [
    "group_numbers_all_patients = np.full(len(data), 0.0)\n",
    "\n",
    "for i, g in enumerate(group_masks):\n",
    "    print(i, end='\\r')\n",
    "    # Pick out which patients are in this group:\n",
    "    patients_inds = np.arange(len(data))[g == True]\n",
    "\n",
    "    group_numbers_all_patients[patients_inds] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93d403-d924-4c67-abe9-fffcd53e1812",
   "metadata": {},
   "source": [
    "## Check group sizes\n",
    "\n",
    "Create a list of how many patients are in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c52803e-ba14-4f0c-beaa-b1edc4570468",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patients_per_group = []\n",
    "\n",
    "for i in range(n_groups):\n",
    "    n_patients = len(np.where(group_numbers_all_patients == i)[0])\n",
    "    n_patients_per_group.append(n_patients)\n",
    "\n",
    "n_patients_per_group = np.array(n_patients_per_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f2bad7-67a8-4361-8855-b2db22521fba",
   "metadata": {},
   "source": [
    "If this is the training data, save a copy of how many patients are in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "564352ab-b41a-412e-9544-14fac46ec349",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training == 1:\n",
    "    df_numbers = pd.DataFrame(\n",
    "        np.stack(\n",
    "            (np.arange(len(n_patients_per_group)), \n",
    "             n_patients_per_group), axis=-1),\n",
    "        columns=['mask_number', 'number_of_patients']\n",
    "    )\n",
    "    \n",
    "    df_numbers.to_csv(f'./uncertainty/{save_str}group_sizes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9cdef-d060-4feb-909b-b09ff8aab28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "How many groups contain zero patients? How many groups contain very few patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f58247-bd48-4723-b51f-bd81c2176255",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_empty = len(np.where(n_patients_per_group == 0)[0])\n",
    "count_low = len(np.where(\n",
    "    (n_patients_per_group > 0) &\n",
    "    (n_patients_per_group < 10) \n",
    ")[0])\n",
    "\n",
    "print(f'Number of empty groups: {count_empty}')\n",
    "print(f'Number of small groups: {count_low}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f1ef8-b436-40e8-b6fe-098c21d64092",
   "metadata": {},
   "source": [
    "Plot distribution of group sizes for all non-empty groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc5e35-5d2b-497f-be6c-1662823529e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_patients_per_group[np.where(n_patients_per_group > 0)], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19e65f-3e71-4499-9201-e0eb33d2f7a1",
   "metadata": {},
   "source": [
    "## Largest groups\n",
    "\n",
    "Sort the group labels by group size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4822b-2ae3-49b2-aa6e-a95d36c872d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_group_sizes = sorted(n_patients_per_group)\n",
    "sorted_groups = np.argsort(n_patients_per_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e3dfc-fa63-426e-a9be-a74a220dd68f",
   "metadata": {},
   "source": [
    "Show the properties of the largest groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1952c8-1808-42ff-844e-5d161c51c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_largest_groups = pd.DataFrame(\n",
    "    np.array(inds_lists)[sorted_groups[::-1][:10]],\n",
    "    columns=[m for m in masks_names]\n",
    ")\n",
    "\n",
    "df_largest_groups['size'] = sorted_group_sizes[::-1][:10]\n",
    "\n",
    "df_largest_groups = df_largest_groups.replace(mask_str_dict)\n",
    "\n",
    "df_largest_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d354d3e-5439-48a3-b8a7-a24dc670e9a3",
   "metadata": {},
   "source": [
    "## Empty groups\n",
    "\n",
    "Show the properties of the size-zero groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fa1ef-4a0a-4a59-8698-38c3c8837e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.where(n_patients_per_group == 0)[0]\n",
    "\n",
    "df_zero_groups = pd.DataFrame(\n",
    "    np.array(inds_lists)[inds],\n",
    "    columns=[m for m in masks_names]\n",
    ")\n",
    "\n",
    "df_zero_groups['size'] = n_patients_per_group[inds]\n",
    "\n",
    "df_zero_groups = df_zero_groups.replace(mask_str_dict)\n",
    "\n",
    "df_zero_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5717f7-539b-4679-8013-e4fc3ce035a6",
   "metadata": {},
   "source": [
    "Show all zero-size groups that do not have onset-to-scan above 4 hours or both precise onset time and onset during sleep. There is no easy logical reason why any remaining groups should have zero size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c3997-9851-488b-b583-84559e733779",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.where(n_patients_per_group == 0)[0]\n",
    "\n",
    "df_zero_groups = pd.DataFrame(\n",
    "    np.array(inds_lists)[inds],\n",
    "    columns=[m for m in masks_names]\n",
    ")\n",
    "\n",
    "df_zero_groups['size'] = n_patients_per_group[inds]\n",
    "\n",
    "z_mask = (\n",
    "    (df_zero_groups['onset_scan'] == 1) |\n",
    "    ((df_zero_groups['precise'] == 1) &\n",
    "     (df_zero_groups['sleep'] == 1))\n",
    ") == False\n",
    "\n",
    "df_zero_groups = df_zero_groups[z_mask]\n",
    "\n",
    "\n",
    "df_zero_groups = df_zero_groups.replace(mask_str_dict)\n",
    "\n",
    "df_zero_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d312e74-1a14-4d15-a8d8-8b858814da59",
   "metadata": {},
   "source": [
    "How many groups have precise=yes and sleep=yes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422d384-f402-4023-a1cb-cf654676d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pd.DataFrame(\n",
    "    np.array(inds_lists)[sorted_groups],\n",
    "    columns=[m for m in masks_names]\n",
    ")\n",
    "\n",
    "df_groups['size'] = sorted_group_sizes\n",
    "\n",
    "ps_mask = (\n",
    "    (df_groups['precise'] == 1) &\n",
    "    (df_groups['sleep'] == 1)\n",
    ")\n",
    "\n",
    "df_groups = df_groups[ps_mask]\n",
    "\n",
    "df_groups = df_groups.replace(mask_str_dict)\n",
    "\n",
    "len(df_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37017e-2e61-446f-898f-d41f3a9c0cbe",
   "metadata": {},
   "source": [
    "## Small groups\n",
    "\n",
    "Show the properties of the small but non-zero groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f10edb-22bb-431e-b63f-e298f56e3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.where(\n",
    "    (n_patients_per_group > 0) &\n",
    "    (n_patients_per_group < 10) \n",
    ")[0]\n",
    "\n",
    "df_small_groups = pd.DataFrame(\n",
    "    np.array(inds_lists)[inds],\n",
    "    columns=[m for m in masks_names]\n",
    ")\n",
    "\n",
    "df_small_groups['size'] = n_patients_per_group[inds]\n",
    "\n",
    "df_small_groups = df_small_groups.replace(mask_str_dict)\n",
    "\n",
    "df_small_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234b83a-6a93-44f8-8c78-869854ce25d8",
   "metadata": {},
   "source": [
    "How many have infarction=No?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de905d06-fec5-486f-947d-207162933670",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_small_groups[df_small_groups['infarction'] == 'No'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c88d4f-bbbb-40e6-8318-326c6fc9d273",
   "metadata": {},
   "source": [
    "Only show small groups with infarction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3d95b-81c2-462a-8f80-9f81b0268470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_groups[df_small_groups['infarction'] == 'Yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef17350-12a5-45d3-8aeb-caa4f800a5e3",
   "metadata": {},
   "source": [
    "## Predict probabilities of thrombolysis\n",
    "\n",
    "The following cell picks out each group of patients in turn. For each group, the machine learning model is used to predict their probabilities of thrombolysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01843d2-e720-4ca9-8f57-0ba9c5262fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test == 0:\n",
    "    print(stop, here, please)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4442f-454b-425c-b770-315dc00518d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_arr = np.full((3, len(data)), 0.0)\n",
    "\n",
    "for i in range(n_groups):\n",
    "    print(i, end='\\r')\n",
    "\n",
    "    # Which patients are in this group?\n",
    "    patients_inds = np.where(group_numbers_all_patients == i)[0]\n",
    "\n",
    "    # Pick out the data for the model for these patients:\n",
    "    patients_here = data.loc[patients_inds]\n",
    "    y_here = y_test[patients_inds].values\n",
    "\n",
    "    # What are their predicted probabilities?\n",
    "    if len(patients_here) > 0:\n",
    "        # Only store them to the nearest %, i.e. round to 2 d.p.\n",
    "        probs = np.round(model.predict_proba(patients_here)[:,1], 2)\n",
    "    else:\n",
    "        probs = np.array([])\n",
    "\n",
    "    # Save the results to the big array:\n",
    "    results_arr[0, patients_inds] = i\n",
    "    results_arr[1, patients_inds] = probs\n",
    "    results_arr[2, patients_inds] = y_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9255655-66b6-4ce6-9105-cce481715594",
   "metadata": {},
   "source": [
    "Convert the results array to a dataframe so that we can label the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc3734-700e-4bf0-a1aa-f344dcc77dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_groups_probs = pd.DataFrame(\n",
    "    results_arr.T,\n",
    "    columns=['mask_number', 'predicted_probs', 'thrombolysis']\n",
    ")\n",
    "\n",
    "df_groups_probs['mask_number'] = df_groups_probs['mask_number'].astype(int)\n",
    "df_groups_probs['thrombolysis'] = df_groups_probs['thrombolysis'].astype(int)\n",
    "\n",
    "df_groups_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662578e9-2749-4e69-8f48-31b9088d622c",
   "metadata": {},
   "source": [
    "Save this dataframe to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f41b64-b2d2-4d20-ac7f-e4039a79d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups_probs.to_csv(f'./uncertainty/{save_str}masks_probabilities.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
